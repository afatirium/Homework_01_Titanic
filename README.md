# Homework_01_Titanic
 **Main task:** Please reproduce our exercises in terms of binary classification on the recommended Titanic set (link: https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv). Please use the **survived** variable as target. The titanic.csv file contains data for 887 of the real Titanic passengers. Each row represents one person. The columns describe different attributes about the person including whether they survived, their age, their passenger-class, their sex etc.


**Some story behind dataset:** *On April 15, 1912, the largest passenger liner ever made collided with an iceberg during her maiden voyage. When the Titanic sank it killed 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships. One of the reasons that the shipwreck resulted in such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others.*


 *If you feel like using another dataset that is dedicated to binary or multiclass classification, feel free to use it.*


**Steps**
1. Load your data and prepare train-test split - check if your data is well balanced in terms of the target variable (if not try to use the stratify strategy in `train_test_split` function - see documentation: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).
2. Create decent EDA/SEDA on training dataset - remember that you can use your statistical data analysis skills. Now you have many more categorical variables available - you can use e.g. Fisher/Chi2 tests (https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.fisher_exact.html), ANOVA analysis (https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.f_oneway.html), box-plots with some grouping (https://plotly.com/python/box-plots/) and many many more.
3. Create some cool features - due to the larger number of categorical variables, you can use something much sexier in addition to one-hot-encoding: http://contrib.scikit-learn.org/category_encoders/. Familiarize yourself with the methods available in this package and if you find something for yourself, use it (remember that you fit the method on the train set, and on the test set you only perform transformations on the already fitted object). Everything in this step depends on your imagination and the number of methods you know :)
4. Create your first logistic regression model (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) as we did with linear regression. Note that in the documentation for default logistic regression L2 regularization is turned on, turn it off first (penalty = None). In addition, in this step you must choose the evaluation functions for you (https://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values). Based on the lecture and the available documentation, select the functions that will be appropriate for your problem (e.g. check if you are dealing with an unbalanced problem and decide what is more important to you, e.g. Precision or Recall optimization). Try to plot two curves that we discussed during our lecture: ROC (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.RocCurveDisplay.html#sklearn.metrics.RocCurveDisplay.from_estimator) and PR (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.PrecisionRecallDisplay.html#sklearn.metrics.PrecisionRecallDisplay.from_predictions). Remember to experiment with different logit models because of the explanatory variables used.
5. Use cross-validation of your choice (if your sample is unbalanced, use cross-validation with stratified, e.g. https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html).
6. Check whether regularization will be helpful in your problem - use three models of regularized logistic regression (ridge, lasso and elastic net). You can use the LogisticRegression object for this (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression) - note that you have three hyperparameters at your disposal: a) penalty - Specify the norm of the penalty; b) C - **Inverse** of regularization strength; c) l1_ratio - this remark only makes sense if you are using elastic net. Try playing with these hyperparameters.
7. Use your chosen hyperparameter tuning method for regularized logistic regression. CheckÂ on the out-of-sample test set whether your results have improved.


